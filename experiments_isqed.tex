\section{Experimental Results}
\label{sec:exp}
% All the algorithms and computations were implemented in Polybori engine~\cite{pbori:JSC09}.
% Our implementation is based on 
% Based on the above discussion, we will: i) model GBR as the
% algebra of unate cube sets; ii) use ZDDs as the implicit
% data-structure for this GBR; and iii) devise efficient implementation
% of GBR by exploiting the special structure imposed by RTTO on the
% ZDD graph.  
% In \cite{Minato:DAC94}, {\it Minato} demonstrated that ZDDs are an
% efficient data-structure for implicit manipulation (algebra) of unate
% cube sets. 
%Since a monomial of a Boolean
%polynomial is a unate cube, we can interpret a Boolean polynomial as a
%set of unate cubes; and each monomial (cube) as a set of
%variables. 
% {\it Minato} has shown (\cite{Minato:DAC93}\cite{Minato:DAC94}) how the set union, intersection and
% difference operations can be performed recursively on the ZDDs, 
% and they have been implemented using the {\it ite-operator (if-then-else)} in
% decision diagrams such as the CUDD \cite{Somenzi:CUDD} package. 
% By analyzing the {structure of ZDDs} for 
% polynomial representation, we show how this 
% GB-reduction can be efficiently implemented using algorithms that
% specifically manipulate the ZDD graph. 

% {\it implicit} characteristic set representation 
% for storing and manipulating polynomials. 
% The same framework 
% is utilized towards implementing incremental rectification check.
% Our implementation utilizes PolyBori’s~\cite{pbori:JSC09} reduction procedure with 
% ZDD~\cite{Minato:DAC93,Minato:DAC94} as the underlying data structure to 
% model the MFR framework. 
% % Our rectification approach operates 
% % over the ring $\ftkwring$, whereas ZDDs can only be used 
% % to represent polynomials and perform reductions in $\ftring$.
% % % We extend these operations to accommodate the sum and product operations
% % % $\pmod{2}$, i.e. polynomial algebra in $\Ftwo[x_1,\dots,x_d]$, by 
% % % manipulating sets of combinations using ZDDs. 
% % However, as the core of our computations is based on a
% % couple of Spoly reductions, it is possible to employ ZDDs
% % ~\cite{Utkarsh:TCAD19}. 
% Taking inspiration from~\cite{Utkarsh:TCAD19}, we make use of the 
% {\it implicit} characteristic set representation 
% for storing and manipulating polynomials. 
% % The same framework 
% % is utilized towards implementing incremental rectification check.
% In addition, we have developed a high level finite field engine
%  to model bit-vector and coefficient computations.
% Further, we have also utilized polynomial algebra tool {\sc Singular}
% ~\cite{DGPS_410} for finding primitive polynomials to help model composite field characteristics.
% Subject to the given variable order, a ZDD represents a 
% Boolean function canonically. Just as with BDDs, every node in a ZDD
% is assigned an index, which corresponds to the variable order imposed
% on the diagram. A detailed description of ZDDs and
% their capabilities for solving logic optimization and sparse
% combinatorial problems can be found in \cite{Minato:DAC93} and
% \cite{Minato:DAC94}. 
% Minato has shown ([94][95]) how the set union, intersection and difference operations
% can be performed recursively on the ZDDs, and they have been implemented using the
% ite-operator (if-then-else) in decision diagrams such as the CUDD [118] package. We extend
% these operations to accommodate the sum and product operations ( mod 2 ) , i.e. polyno-
% mial algebra in \Fkn, by manipulating sets of combinations using ZDDs.
% Based on the above discussion, we will: i) model GBR as the algebra of unate cube
% sets; ii) use ZDDs as the implicit data-structure for this GBR; and iii) devise efficient
% implementation of GBR by exploiting the special structure imposed by RTTO on the ZDD
% graph.where each unate cube (monomial) represents one combination,
%and each literal represents an object chosen in the combination.
% -- resembling a
%classical logic synthesis problem. 
%Then the ZDD can also be used to represent
%polynomials where the monomials can be obtained the same way the cubes
%are obtained for the equivalent set. 
% Once verification detects presence of bugs, we use heuristics (Section.~\ref{subsec:target_nets})  
% to identify targets for MFR. Following this, we apply Thm.~\ref{Thm:rect} to perform rectification check. Once rectification check passes, we apply the approach described in Section VI of Rao et al.~\cite{Vkrao:FMCAD18} to compute 
% a rectification function.
% In the result tables, the rows marked with an '*' indicate that the patch size $m$ is 
% such that $m \nmid n$, hence requiring operations in composite field $\Fkk$, where $k = LCM(m,n)$.
 % IC = Incremental rectification c$$heck,

We implement our approach as a custom software by integrating PolyBori~\cite{pbori:JSC09} libraries,
{\sc Singular}~\cite{DGPS_410} libraries, and a custom high level finite field engine.
We utilize PolyBori’s reduction procedure to implement the division 
$f\xrightarrow{F'_l\cup F'_{0}}_+ rem_l,$ $ 1 \leq l \leq 2^m$. The libraries from {\sc Singular} 
are used to compute $P_k(X)$ and to model composite field characteristics.
The custom finite field engine is employed in modeling bit-vector and coefficient computations,
and is utilized in the overall decision procedure. The experiments are performed on a 3.5GHz 
Intel(R) $\text{Core}^{\text{TM}}$ i7-4770K Quad-Core CPU with 32 GB RAM.

Table~\ref{exptbl} presents the results of our approach when 
performing the MFR check on two modular multipliers (Mastrovito and Montgomery), and circuits
that perform Point Addition over elliptic curves. The MFR check is performed against 
their respective polynomial specifications. 
These designs form the core components for performing encryption, 
decryption and authentication in Elliptic Curve Cryptography (ECC).
These Benchmarks are taken from~\cite{lv:tcad2013} and synthesized using the {\it abc} 
tool~\cite{abc} with a two input gate library.
We introduce bugs in the synthesized netlists by means of gate and wiring 
modifications at various topological levels: some closer to PIs, 
some in the middle of the circuit, and some near POs.
The column BO for each benchmark corresponds to the total number of POs affected by the 
gate and wiring modifications. 

In the results table, column 2 ($n$) denotes the datapath size for the corresponding benchmark,
and the columns marked $G$ denote the total number of gates for the respective synthesized netlists.
 In our experiments, we check the rectifiability of circuits, where the number of targets
is chosen from $m=\{2,3,5,7\}$. However, our approach doesn't constrain the number 
of targets to check for rectifiability. For cases where the targets admit rectification 
(Rows 1-10), the $m$ targets are chosen to lie very close to the gate outputs 
where the bugs were introduced, while for the cases where the targets 
do not admit rectification (Rows 11-18), the $m$ targets are chosen away 
from the cone of influence where bugs were introduced.

PBS denotes the time taken to build the ZDD models for the implementation
and the specification of the corresponding 
benchmarks using the Polybori engine. Column AM denotes the maximum
resident memory size recorded for these models,  
averaged across benchmarks for a given datapath size $n$.
VMS denotes the time
taken to perform verification, compute $P_k(X)$, and setup MFR check.
The execution time required for RC (Thm.~\ref{Thm:rect}) depends 
on the number ($m$) and selection of the targets in $W$, as well as the
computed $P_k(X)$. These parameters result in different sizes of $rem_l$. The larger the size, 
the longer it takes to perform the rectification check. This is depicted in the table for 
Montgomery multipliers, where the rectification check for the 409-bit* circuit takes 
significantly longer than for the 571-bit$\td~\text{circuit}.$ 

% For Mastrovito and Montgomery multipliers, the specification 
% polynomial is given as $f: = A\times B \pmod{ P_n(X)}$, 
% where $P_n(x)$ is a given primitive polynomial for the datapath size $n$. 
% In mastrovito architecture, the product $A \times B$ is computed using an 
% array multiplier architecture, and then the result is reduced modulo $P(X)$.
% Montgomery architectures are considered more efficient than Mastrovito for exponentiation, 
% as they do not require explicit reduction modulo $P(X)$ after each step. 
% The Point addition block implements operations required for the task of encryption, 
% decryption and authentication in Elliptic Curve Cryptography (ECC). 
% Modern approaches represent the points in projective
% coordinate systems, {\it e.g.}, the L$\acute{o}$pez-Dahab (LD) projective coordinate, 
% due to which the point addition operation can be implemented as polynomials in the field.
% The results table demonstrates the application of our approach towards
% checking the MFR in the most complex Point addition implementation block against
% its specification $D= B^2\cdot(C + aZ_1^2)$. 

We compare our approach against the cofactor reduction algorithm (Alg. 1) 
presented in~\cite{MF_Huang:DATE12}. We implemented the Alg. 1 of~\cite{MF_Huang:DATE12} 
using {\it abc/MiniSAT}. Empirical data shows that the rectification check for 
circuits beyond 16-bits timed out (3 hours). Specifically, the final UNSAT 
check on line 4 of the Alg. 1 is infeasible for the benchmarks
presented in our results table, and hence the comparision is omitted.   

% \subsection{Word level specification v/s Barrett reduction implementation}
% Barrett reduction
% %~\cite{barrett}
% is the other widely used multiplier design
% method adopted in cryptography system designs. 
% Based on Barrett reduction, a multiplier can be designed in two steps:
% multiplication $R = A \times B$ and a subsequent Barrett reduction G =
% R (mod P). ~\autoref{bartvsspec} shows results for debugging and rectification of
% Barrett multipliers against a polynomial specification. 
% Since the SAT-based approach cannot be applied against a word level specification polynomial, 
% we perform experiments while using another multiplier implementation as the specification.
%% ~\autoref{montfig} shows the structure of a Montgomery
%% multiplier. Each MR block computes $A\cdot B\cdot R^{-1}$, where $R$
%% is selected as a power of a base ($\alpha^{k}$) and $R^{-1}$ is the multiplicative 
%% inverse of $R$ in $\mathbb{F}_{2^k}$. As this operation cannot compute $A\cdot B$
%% directly, we need to pre-compute $A\cdot R$ and $B\cdot R$ as shown in the~\autoref{montfig}. 
%% We denote the leftmost
%% two blocks as Block A (upper) and B (lower), the middle block as Block
%% C and the output block as Block D.
% We have presented results for GBR
%on both \textit{flattened} and \textit{hierarchical} netlists of these
% multipliers.
% \subsection{Verification between a specification and implementation
%   given as gate level circuits: Mastrovito v/s Montgomery multipliers}
% ~\autoref{masusmontspec} presents the results of our approach when the
%  bugs were introduced in a gate level circuit checked for rectifiability with specification
%  given in terms of gate-level circuit as well.
% \begin{table}[hbt]
% \centering
% \caption{{\footnotesize Rectification for Mastrovito circuit with Montgomery circuit as specification. Time is in seconds; rows marked '*' indicates $m \nmid n$; Benchmark = Finite field benchmark, $n$ = Datapath Size, \#Gates = No. of gates, K = $10^3$, $m$ = patch size, $k$ = encompassing composite field size, PF = time for polynomial factorization and computing minpoly for the composite field, RC = time for rectification check}}
% \label{masusmontspec}
% \begin{tabular}{| c | c | c | c | c | c |} \hline
% {\textbf{n}}& {\textbf{\#Gates}} & {\textbf{m}} & {\textbf{k}} & {\textbf{PF}} & {\textbf{RC}} \\ \hline 
% 12 & - & 2 & 12 & NA & --\\ \hline
% 16 & - & 2 & 16 & NA & --\\ \hline
% *16 & - & 3 & 48 & -- & --\\ \hline
% *20 & - & 3 & 60 & -- & --\\ \hline
% 32 & - & 2 & 32 & NA & --\\ \hline
% 48 & - & 3 & 48 & NA & --\\ \hline
% 64 & - & 2 & 64 & Na & --\\ \hline
% \end{tabular}
% \end{table}
\section{Conclusion}\label{sec:conc}
This paper presents an automated approach using techniques from 
symbolic computer algebra to determine multi-fix rectifiability of 
faulty finite field arithmetic circuits at a given set of targets. 
The underlying theory and algorithms are based on \Grobner 
basis reductions, the Strong Nullstellensatz principle, ideal membership testing,
and finite fields.
The efficiency of our approach is derived by interpreting the targets 
as a bit-vector and enabling word-level reasoning.
We propose new mathematical insights to overcome the
challenges associated with formulating the problem over a composite field.
% Experimental results demonstrate the efficacy of our approach
% against contemporary techniques. 
As future work, we are
investigating subsequent computation of multi-fix rectification 
functions, also at the word-level. Further, we are also exploring
techniques to improve the efficiency of rectification check implementation.

%Such a
%word-level paradigm is made possible by collectively exploiting finite
%field theories and computational algebraic geometry, in the context of
%rectification.

% Should we mention word level something?
% Should we not re-acronymize MFR?
% This paper presents an automated MFR check approach to of buggy finite field arithmetic circuits
% the ully automated symbolic computer algebra approach towards.
% %n order to compute a desired patch function, we need to account for the 
% % following key synthesis aspects in our rectification formulation:
% % \bi
% % \item 
% % \item Computing rectification functions in terms of internal nets.
% % % \item Selection of the rectification targets.
% % \ei
% % The gates of the circuit C are modeled as a set of polynomials where the variables 
% % are the nets of the circuit. An order on the variables is derived from 
% % the topology of the circuit, and a lex term order (RTTO $>$) is imposed on the polynomials. 
% Given a specification, a buggy circuit implementation, and a set of $m$-target nets,
% we perform rectifibility check at these nets. 
% The underlying theory and algorithms are based on \Grobner basis reductions, Nullstellensatz, and ideal membership test.  
% The experimental results demonstrate the efficacy of our approach for finite field 
% arithmetic circuits. 
% As part of our future work, we are working on formulating rectification check in terms of internal nets. 
% Further, we are also investigating the extension of this approach to integer arithmetic circuits.
